{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import ensemble\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Load data\n",
    "#data = pd.read_csv('../../RealData/RealData.csv')\n",
    "data = pd.read_csv('../../SynData/data/GeneratedData.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Training and Testing Data\n",
    "X = data[['throughput']]\n",
    "y = data['CPU']\n",
    "X = X.fillna(X.mean())\n",
    "scaler = MinMaxScaler(feature_range=(0, 100))\n",
    "X = scaler.fit_transform(X)\n",
    "#X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=101)\n",
    "\n",
    "n = len(X)\n",
    "kf = KFold(n_splits=5)\n",
    "fold = 0\n",
    "for train_index, test_index in kf.split(X):\n",
    "    fold += 1\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 490 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 972 out of 972 | elapsed:   21.9s finished\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'loss': 'huber', 'max_depth': 6, 'min_samples_split': 12, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# #############################################################################\n",
    "# Fit regression model\n",
    "params = {'n_estimators': [50, 100, 200], 'max_depth':[2, 4, 6], 'min_samples_split': [2, 4, 12],\n",
    "          'learning_rate': [0.1, 0.01, 0.001], 'loss': ['ls', 'lad', 'huber', 'quantile']}\n",
    "gb = ensemble.GradientBoostingRegressor()\n",
    "clf = GridSearchCV(gb, params, verbose=1, n_jobs=-1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.602589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.759699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.632279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.775595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.660100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.699810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.775595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.612980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.595453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.730181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.772599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.653026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.727428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.730181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.740181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.730181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.763667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.783595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.653026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.774474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.798933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.798933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.798933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.798933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.798933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.798933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.798933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.798933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.798933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.798933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.740181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.706821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.763667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.700457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.643656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.740181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.772599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.742672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.614639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.767507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual  Predicted\n",
       "0       0.9   0.602589\n",
       "1       0.9   0.759699\n",
       "2       0.9   0.632279\n",
       "3       0.9   0.775595\n",
       "4       0.9   0.660100\n",
       "5       0.9   0.699810\n",
       "6       0.9   0.775595\n",
       "7       0.9   0.612980\n",
       "8       0.9   0.595453\n",
       "9       0.9   0.730181\n",
       "10      0.9   0.772599\n",
       "11      0.9   0.653026\n",
       "12      0.9   0.727428\n",
       "13      0.9   0.730181\n",
       "14      0.9   0.740181\n",
       "15      0.9   0.730181\n",
       "16      0.9   0.763667\n",
       "17      0.9   0.783595\n",
       "18      0.9   0.653026\n",
       "19      0.9   0.774474\n",
       "20      0.9   0.798933\n",
       "21      0.9   0.798933\n",
       "22      0.9   0.798933\n",
       "23      0.9   0.798933\n",
       "24      0.9   0.798933\n",
       "25      0.9   0.798933\n",
       "26      0.9   0.798933\n",
       "27      0.9   0.798933\n",
       "28      0.9   0.798933\n",
       "29      0.9   0.798933\n",
       "..      ...        ...\n",
       "290     1.0   0.740181\n",
       "291     1.0   0.706821\n",
       "292     1.0   0.763667\n",
       "293     1.0   0.700457\n",
       "294     1.0   0.643656\n",
       "295     1.0   0.740181\n",
       "296     1.0   0.772599\n",
       "297     1.0   0.742672\n",
       "298     1.0   0.614639\n",
       "299     1.0   0.767507\n",
       "300     1.0   0.798933\n",
       "301     1.0   0.798933\n",
       "302     1.0   0.798933\n",
       "303     1.0   0.798933\n",
       "304     1.0   0.798933\n",
       "305     1.0   0.798933\n",
       "306     1.0   0.798933\n",
       "307     1.0   0.798933\n",
       "308     1.0   0.798933\n",
       "309     1.0   0.798933\n",
       "310     1.0   0.798933\n",
       "311     1.0   0.798933\n",
       "312     1.0   0.798933\n",
       "313     1.0   0.798933\n",
       "314     1.0   0.798933\n",
       "315     1.0   0.798933\n",
       "316     1.0   0.798933\n",
       "317     1.0   0.798933\n",
       "318     1.0   0.798933\n",
       "319     1.0   0.798933\n",
       "\n",
       "[320 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = clf.predict(X_test)\n",
    "y_test = np.array(list(y_test))\n",
    "prediction= np.array(prediction)\n",
    "df = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': prediction.flatten()})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9\n 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9\n 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9\n 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9\n 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9\n 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9\n 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9\n 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9\n 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 1.  1.\n 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6420203d8cb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtest_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    460\u001b[0m                              % self.best_estimator_)\n\u001b[1;32m    461\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultimetric_\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m_passthrough_scorer\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_passthrough_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;34m\"\"\"Function that wraps estimator.score\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         return r2_score(y, self.predict(X), sample_weight=sample_weight,\n\u001b[0m\u001b[1;32m    329\u001b[0m                         multioutput='variance_weighted')\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   2425\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2426\u001b[0m         \"\"\"\n\u001b[0;32m-> 2427\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2428\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    545\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9\n 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9\n 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9\n 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9\n 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9\n 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9\n 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9\n 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9\n 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 0.9 1.  1.\n 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# Plot training deviance\n",
    "\n",
    "# compute test set deviance\n",
    "test_score = np.zeros((100,), dtype=np.float64)\n",
    "\n",
    "for i, y_pred in enumerate(clf.predict(X_test)):\n",
    "    test_score[i] = clf.score(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Deviance')\n",
    "plt.plot(np.arange(params['n_estimators']) + 1, clf.train_score_, 'b-',\n",
    "         label='Training Set Deviance')\n",
    "plt.plot(np.arange(params['n_estimators']) + 1, test_score, 'r-',\n",
    "         label='Test Set Deviance')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Boosting Iterations')\n",
    "plt.ylabel('Deviance')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.19695352569837515\n",
      "MSE: 0.04628076411630917\n",
      "RMSE: 0.21512964490350736\n"
     ]
    }
   ],
   "source": [
    "#Model Evaluation\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, prediction))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, prediction))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, prediction)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x115d886d8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(y_test-prediction,bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = '../models/gradientBoostingReg_model.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10104195])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
